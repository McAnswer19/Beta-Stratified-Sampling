{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:53:01.452915Z",
     "start_time": "2020-04-26T13:53:01.447919Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hdi import hpd_grid\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:43:18.136124Z",
     "start_time": "2020-04-26T15:43:18.076316Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tree_Inference_Object():\n",
    "    # We should expand this class later to support non-uniform priors? \n",
    "    \n",
    "    def __init__(self, observation_array, labels, confidence, granularity): \n",
    "        \n",
    "        assert len(observation_array) == len(labels)     # Every frequency count should have a name. \n",
    "\n",
    "        self.observation_array = observation_array      # Array to hold the actual, observed frequencies\n",
    "        self.labels = labels                            # Names for each outcome type. \n",
    "        self.confidence = confidence                    # Overall confidence for the intervals.\n",
    "        \n",
    "        self.granularity = granularity                  # Number of random deviates to sample for the beta \n",
    "                                                        #  when computing the density.\n",
    "\n",
    "        self.level = 1                                  # Level of the tree we are at. Root = 1\n",
    "\n",
    "        \n",
    "        self.interval_array = np.zeros(shape = (len(observation_array), 2)) # Empty array to hold the upper and \n",
    "                                                                            # lower bounds for each variable\n",
    "\n",
    "        self.credmass_per_cell =self.confidence**(1/(len(observation_array) - 1))   # Size of the credibility region\n",
    "                                                                                    # per cell. \n",
    "\n",
    "        self.outcome_size = len(self.observation_array)                  # Number of outcome types. \n",
    "                                                                          # 'K' for dirichlet distribution. \n",
    "\n",
    "        \n",
    "        self.tree_height = np.ceil(np.log2(self.outcome_size))         # Height of our binary tree. \n",
    "\n",
    "        \n",
    "\n",
    "    def update_obs_array(self, new_obs_array):\n",
    "        \"\"\"helper function for changing the frequency counts. Use care, as the intervals will have\n",
    "        to be recomputed.\"\"\"                  \n",
    "                          \n",
    "        self.observation_array = new_obs_array\n",
    "        \n",
    "        # Then change all of the dependent variables. \n",
    "        self.interval_array = np.zeros(shape = (len(self.observation_array), 2))\n",
    "        self.credmass_per_cell =self.confidence**(1/(len(self.observation_array) - 1))\n",
    "        self.outcome_size = len(self.observation_array)\n",
    "        self.tree_height = np.ceil(np.log2(self.outcome_size))\n",
    "        \n",
    "    def update_labels_array(self, new_labels): \n",
    "        \"\"\"Helper function for changing the label names\"\"\"\n",
    "                          \n",
    "        assert len(new_labels) == len(self.observation_array)\n",
    "                          \n",
    "        self.labels = new_labels\n",
    "        \n",
    "        \n",
    "    def __str__(self): \n",
    "        output_string = \"labels {} \\n observations {} \\n  \\n\".format(self.labels, self.observation_array)\n",
    "        \n",
    "        return(output_string)\n",
    "        \n",
    "    def return_normalized_interval_sample(self, num_samples): \n",
    "        \"\"\"returns stochastic samples from the tree. Probs are different each time it is called.\"\"\"\n",
    "        \n",
    "        \n",
    "        # For each variable, randomly pick a point in its interval, and then normalize for all intervals\n",
    "        # to get a multinomial.Then return num_samples from that multinomial. \n",
    "        prob_list = []\n",
    "        for i in range(len(self.observation_array)): \n",
    "            lower = self.interval_array[i, 0 ]\n",
    "            upper = self.interval_array[i, 1 ] \n",
    "\n",
    "            selected_prob = np.random.uniform(lower, upper)\n",
    "            prob_list.append(selected_prob)\n",
    "                \n",
    "                \n",
    "        prob_list = np.array(prob_list)\n",
    "        prob_list = prob_list/np.sum(prob_list)\n",
    "            \n",
    "        returned_samples = np.random.choice(a = self.labels, size = num_samples, p = prob_list)\n",
    "                \n",
    "                \n",
    "        return(returned_samples)\n",
    "    \n",
    "    def get_interval_sample(self, number_of_samples = 50, interval_type = \"mix\"):\n",
    "        \"\"\"Returns samples from the tree from a number of options\"\"\"\n",
    "        interval_type = interval_type.lower()\n",
    "        assert interval_type in [\"lower\", \"upper\", \"midrange\", \"mix\"]\n",
    "        \n",
    "        \n",
    "        # Four options only: \n",
    "        # lower = the lower interval edge for each variable. \n",
    "        # upper = the upper interval edge for each variable.\n",
    "        # midrange = the midrange for each variable\n",
    "        # mix  = for each sample, randomly choose from any of the above three options with equal probability. \n",
    "\n",
    "        if interval_type == \"lower\":\n",
    "            normalized_probs = self.interval_array[:, 0]/np.sum(self.interval_array[:, 0])\n",
    "            return_list = np.random.choice(a = self.labels, size = number_of_samples, p = normalized_probs)\n",
    "        \n",
    "        elif interval_type == \"upper\":\n",
    "            normalized_probs = self.interval_array[:, 1]/np.sum(self.interval_array[:, 1])\n",
    "            return_list = np.random.choice(a = self.labels, size = number_of_samples, p = normalized_probs)\n",
    "\n",
    "        elif interval_type == \"midrange\":\n",
    "            normalized_probs = (self.interval_array[:, 0] + self.interval_array[:, 1])/2\n",
    "            normalized_probs = normalized_probs/np.sum(normalized_probs)\n",
    "            return_list = np.random.choice(a = self.labels, size = number_of_samples, p = normalized_probs)\n",
    "\n",
    "        elif interval_type == \"mix\": \n",
    "            return_list = np.empty(shape = number_of_samples, dtype= np.str)\n",
    "            choice_list = np.random.randint(low = 0, high = 2, size = number_of_samples) \n",
    "            for counter, choice in enumerate(choice_list): \n",
    "                \n",
    "                if choice == 0: \n",
    "                    normalized_probs = self.interval_array[:, 0]/np.sum(self.interval_array[:, 0])                    \n",
    "                    return_list[counter] = np.random.choice(a = self.labels, size = 1, p = normalized_probs)[0]\n",
    "                    \n",
    "                elif choice == 1: \n",
    "                    normalized_probs = self.interval_array[:, 1]/np.sum(self.interval_array[:, 1])\n",
    "                    return_list[counter] = np.random.choice(a = self.labels, size = 1, p = normalized_probs)[0]\n",
    "                    \n",
    "                elif choice == 2: \n",
    "                    normalized_probs = (self.interval_array[:, 0] + self.interval_array[:, 1])/2\n",
    "                    normalized_probs = normalized_probs/np.sum(normalized_probs)\n",
    "                    return_list[counter] = np.random.choice(a = self.labels, size = 1, p = normalized_probs)[0]\n",
    "                    \n",
    "                    \n",
    "        return(return_list)\n",
    "    \n",
    "    def __recursive_branching(self, valid_range):\n",
    "        \"\"\"private function for getting samples from the tree. Should only ever be called by \n",
    "        itself and get_tree_sample()\"\"\"\n",
    "        \n",
    "        # Code largely adapted from XXX. \n",
    "        midpoint = np.floor(np.mean([valid_range[0], valid_range[-1]]))\n",
    "        left_range = self.__get_inclusive_range(valid_range[0], midpoint)\n",
    "        right_range = self.__get_inclusive_range(midpoint +  1, valid_range[-1])\n",
    "\n",
    "        # A and B for the beta distribution. \n",
    "        b = np.sum(self.observation_array[left_range]) \n",
    "        a = np.sum(self.observation_array[right_range]) \n",
    "        \n",
    "       # We discount each one by our distance from the top of the tree. \n",
    "        b = b* 2**(self.level - self.tree_height)\n",
    "        a = a * 2**(self.level - self.tree_height)\n",
    "        \n",
    "\n",
    "        # pseudocounts for each side of a cell. Each outcome type/variable increments them by one. \n",
    "        left_base = len(self.observation_array[left_range])\n",
    "        right_base = len(self.observation_array[right_range])\n",
    "        \n",
    "        # Freeze the distribution, then get a single random deviate. \n",
    "        frozen_beta_dist = beta(a = (a + right_base), b = (b + left_base))\n",
    "        beta_deviate = frozen_beta_dist.rvs(1).item()\n",
    "\n",
    "        # direction is chosen stochasticly based on whatever the deviate was. \n",
    "        direction = np.random.choice(a = [\"left\", \"right\"], size= 1, p = [1 - beta_deviate, beta_deviate])\n",
    "\n",
    "        \n",
    "         # If they are right next to each other, then we are at a leaf. \n",
    "        if len(left_range) == 1 and len(right_range) == 1:            \n",
    "            if direction == \"left\":\n",
    "                return(self.labels[left_range.item()])\n",
    "                \n",
    "            elif direction == \"right\": \n",
    "                return(self.labels[right_range.item()])\n",
    "\n",
    "            \n",
    "        # if the cell only branches on side side instead of two or none. \n",
    "        elif (len(left_range) == 1 or len(right_range) == 1):\n",
    "            if direction == \"left\":\n",
    "                return(self.__recursive_branching(left_range))\n",
    "            else: \n",
    "                return(self.labels[right_range.item()])\n",
    "            \n",
    "            \n",
    "            \n",
    "        else: \n",
    "            if direction == \"left\": \n",
    "                return(self.__recursive_branching(left_range))\n",
    "                \n",
    "                \n",
    "            elif direction == \"right\": \n",
    "                return(self.__recursive_branching(right_range))\n",
    "\n",
    "            \n",
    "        \n",
    "    def get_tree_sample(self, num_samples):\n",
    "        \"\"\"Returns a sample from the actual tree. For each sample, we walk down the tree\n",
    "            stochasticaly and retrieve a sample. \"\"\"\n",
    "        return_list = []\n",
    "        \n",
    "        # we need a valid range to supply to __recursive_branching()\n",
    "        valid_range = np.linspace(start= 0  , stop = len(self.observation_array), \n",
    "                                  num = len(self.observation_array), endpoint= False)\n",
    "        \n",
    "        # Converting them to np.int, as by default np.linspace returns doubles. \n",
    "        valid_range = valid_range.astype(np.int)\n",
    "        \n",
    "        for sample in range(num_samples):\n",
    "            return_list.append(self.__recursive_branching(valid_range))\n",
    "            \n",
    "        return(return_list)\n",
    "   \n",
    "    def scramble_order(self):\n",
    "        \"\"\"Helper function that scrambles the order of the labels and frequency counts.\"\"\"\n",
    "        \n",
    "        scrambled_indices = np.linspace(start = 0, stop = len(self.observation_array), \n",
    "                                        num= len(self.observation_array), endpoint = False)\n",
    "        scrambled_indices = np.random.choice(a = scrambled_indices, replace= False, size = len(scrambled_indices))\n",
    "        \n",
    "        scrambled_indices = scrambled_indices.astype(np.uint)\n",
    "\n",
    "        # we scramble the observation array the variable names, and the interval array.  \n",
    "        new_obs_array = np.zeros(shape = self.observation_array.shape)\n",
    "        new_labels = [\"empty\"] * len(self.labels)\n",
    "        new_interval_array = np.zeros(self.interval_array.shape)\n",
    "        \n",
    "        for i in range(len(self.observation_array)): \n",
    "            \n",
    "            # things to scramble self.observation_array, self.labels, self.interval_array\n",
    "            \n",
    "            new_obs_array[scrambled_indices[i]] = self.observation_array[i]\n",
    "            new_labels[scrambled_indices[i]] = self.labels[i]\n",
    "                          \n",
    "            new_interval_array[scrambled_indices[i], 0] = self.interval_array[i, 0]\n",
    "            new_interval_array[scrambled_indices[i], 1] = self.interval_array[i, 1]\n",
    "                          \n",
    "        self.observation_array = new_obs_array\n",
    "        self.labels = new_labels\n",
    "        self.interval_array = new_interval_array\n",
    "        \n",
    "    def __get_inclusive_range(self, left_indice, right_indice): \n",
    "        \"\"\"Private helper function for getting inclusive range as a numpy array. \n",
    "        Makes the code more convenient as by default python indexing is [inclusive, exclusive]\n",
    "        unline in R\"\"\"\n",
    "        \n",
    "        # The right indice should never be less than the left indice, ever. \n",
    "        assert right_indice >= left_indice\n",
    "        \n",
    "        # If they are the same (i.e. we are at a leaf), just return a np array holding a scalar value. \n",
    "        if right_indice == left_indice: \n",
    "            \n",
    "            inclusive_range = np.array([left_indice])\n",
    "            inclusive_range = inclusive_range.astype(np.int)\n",
    "            \n",
    "        else: \n",
    "            inclusive_range = np.linspace(start= left_indice, stop = right_indice, \n",
    "                                      num = np.int(right_indice - left_indice) + 1, \n",
    "                                      endpoint= True)\n",
    "            inclusive_range = inclusive_range.astype(np.int)\n",
    "\n",
    "        return(inclusive_range)\n",
    "    \n",
    "    \n",
    "    def display_results(self):\n",
    "        \"\"\"Displays the results of the inference: intervals and variable names.\"\"\"\n",
    "        \n",
    "        print(\"With {}% confidence, the intervals are:\".format(self.confidence * 100))\n",
    "        print(\"--------------------------------------\")\n",
    "        \n",
    "        for counter, val in enumerate(self.labels):\n",
    "        \n",
    "            lower_val = self.interval_array[counter, 0]\n",
    "            upper_val = self.interval_array[counter, 1] \n",
    "\n",
    "\n",
    "            output_string = \"{} \\n lower {} \\n upper  {}\".format(self.labels[counter], lower_val, upper_val)\n",
    "            print(output_string)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "    \n",
    "    def __handle_edge_case(self):\n",
    "        \"\"\"Private helper method for handling edge cases. I.E. when the number of variables \n",
    "        is less than or equal to 3.\"\"\"\n",
    "        \n",
    "        if len(self.observation_array) <= 1:\n",
    "            print(\"Error: number of categories should be at least 2\")\n",
    "            raise Exception \n",
    "            \n",
    "        elif len(self.observation_array) == 2:\n",
    "            b = 1 + self.observation_array[0]\n",
    "            a = 1 + self.observation_array[1]\n",
    "            \n",
    "            frozen_beta_dist = beta(a = a, b = b)\n",
    "            beta_deviates = frozen_beta_dist.rvs(self.granularity)\n",
    "            \n",
    "            interval, _, _, _ = hpd_grid(sample = beta_deviates, \n",
    "                                                 alpha = self.credmass_per_cell, roundto= 6)\n",
    "            \n",
    "            \n",
    "            # Deshelling, as by default the current interval is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "            \n",
    "            inverse_interval = (1 - current_interval[::-1])\n",
    " \n",
    "            self.interval_array[0, 0]   = min(inverse_interval)\n",
    "            self.interval_array[0, 1]   = max(inverse_interval)\n",
    "            self.interval_array[1, 0]  = min(current_interval)\n",
    "            self.interval_array[1, 1]  = max(current_interval)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # This is the tricky one. Basically, We just do all the computation by hand \n",
    "        # without any clever recursion. Cumbersome, but it works. \n",
    "        elif len(self.observation_array) == 3:\n",
    "            b = 2 + np.sum(self.observation_array[[0, 1]])\n",
    "            a = 1 + self.observation_array[2]\n",
    "            \n",
    "            frozen_beta_dist = beta(a = a, b = b)\n",
    "            beta_deviates = frozen_beta_dist.rvs(self.granularity)\n",
    "            \n",
    "            current_interval, _, _, _ = hpd_grid(sample = beta_deviates, \n",
    "                                                 alpha = self.credmass_per_cell, roundto= 6)\n",
    "            \n",
    "            \n",
    "            # Deshelling, as by default the current interval returned by hpd_grid is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "            \n",
    "            previous_inverse_interval = (1 - current_interval[::-1])\n",
    " \n",
    "            self.interval_array[2, 0]   = min(current_interval)\n",
    "            self.interval_array[2, 1]   = max(current_interval)\n",
    "        \n",
    "        \n",
    "            # cleaning and renaming current interval, just to make things easier. \n",
    "            previous_interval = current_interval\n",
    "            del current_interval\n",
    "            \n",
    "            self.level += 1\n",
    "    \n",
    "## -------------- This represents where we would normally call construct_tree() a second time. Here, \n",
    "# -------------- we just recompute manually and keep going. \n",
    "            \n",
    "            b = 1 + self.observation_array[[0]]\n",
    "            a = 1 + self.observation_array[1]\n",
    "            \n",
    "            b = b* 2**(self.level - self.tree_height)\n",
    "            a = a * 2**(self.level - self.tree_height)\n",
    "            \n",
    "            frozen_beta_dist = beta(a = a, b = b)\n",
    "            beta_deviates = frozen_beta_dist.rvs(self.granularity)\n",
    "            \n",
    "            current_interval, _, _, _ = hpd_grid(sample = beta_deviates, \n",
    "                                                 alpha = self.credmass_per_cell, roundto= 6)\n",
    "            \n",
    "            \n",
    "            # Deshelling, as by default the current interval returned by hpd_grid is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "            \n",
    "            current_inverse_interval = (1 - current_interval[::-1])\n",
    "            \n",
    "            current_interval = current_interval * previous_inverse_interval\n",
    "            \n",
    "            # Finally, we get to write the results to the array. \n",
    "            self.interval_array[1, 0]   = min(current_interval)\n",
    "            self.interval_array[1, 1]   = max(current_interval)\n",
    "            self.interval_array[0, 0]   = min(current_inverse_interval)\n",
    "            self.interval_array[0, 1]   = max(current_inverse_interval)\n",
    "            \n",
    "            self.level -= 1\n",
    "        \n",
    "        else: \n",
    "            print(\"Error: something has gone wrong.\")\n",
    "            raise Exception\n",
    "        \n",
    "        \n",
    "        \n",
    "    def construct_tree(self, valid_range = None, previous_interval = None):\n",
    "        \"\"\"Primary function that builds the tree and computes confidence intervals for each variable. \n",
    "         Calls itself recursively. \"\"\"\n",
    "        \n",
    "        \n",
    "        # Handle the edge case if there are three or less variables. \n",
    "        if len(self.observation_array) <= 3: \n",
    "            self.__handle_edge_case()\n",
    "            return()\n",
    "            \n",
    "        \n",
    "        if valid_range is None: # If we are starting at the root.\n",
    "            \n",
    "            midpoint = np.floor((len(self.observation_array) - 1)/2)\n",
    "            left_range = self.__get_inclusive_range(0, midpoint)\n",
    "            right_range = self.__get_inclusive_range(midpoint + 1, len(self.observation_array) - 1)\n",
    "             \n",
    "        else:  # Standard case otherwise.. \n",
    "            midpoint = np.floor(np.mean([valid_range[0], valid_range[-1]]))\n",
    "            left_range = self.__get_inclusive_range(valid_range[0], midpoint)\n",
    "            right_range = self.__get_inclusive_range(midpoint +  1, valid_range[-1])\n",
    "            \n",
    "        # A and B for the beta distribution. \n",
    "        b = np.sum(self.observation_array[left_range]) \n",
    "        a = np.sum(self.observation_array[right_range]) \n",
    "        \n",
    "       # We discount each one by our distance from the top of the tree. \n",
    "        b = b* 2**(self.level - self.tree_height)\n",
    "        a = a * 2**(self.level - self.tree_height)\n",
    "        \n",
    "\n",
    "        # pseudocounts for each side of a cell. Each outcome type/variable increments them by one. \n",
    "        left_base = len(self.observation_array[left_range])\n",
    "        right_base = len(self.observation_array[right_range])\n",
    "        \n",
    "        \n",
    "        # Freeze the distribution, then get random deviates for the density estimator later on. \n",
    "        frozen_beta_dist = beta(a = (a + right_base), b = (b + left_base))\n",
    "        beta_deviates = frozen_beta_dist.rvs(self.granularity)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Next, we branch depending on where we are in the tree. \n",
    "\n",
    "        \n",
    "        # they are both length 1, we must be at a leaf. \n",
    "        if len(left_range) == 1 and len(right_range) == 1:     \n",
    "            current_interval, _, _, _ = hpd_grid(sample = beta_deviates, \n",
    "                                                 alpha = self.credmass_per_cell, roundto= 6)\n",
    "            \n",
    "            # Deshelling, as by default the current interval is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "\n",
    "\n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "\n",
    "            current_inverse_interval = (1 - current_interval[::-1])\n",
    "\n",
    "            # self.level += 1                 # Is this a bug???\n",
    "\n",
    "            new_left_interval = previous_interval * current_inverse_interval \n",
    "            new_right_interval = previous_interval *  current_interval\n",
    " \n",
    "            self.interval_array[left_range, 0]   = min(new_left_interval)\n",
    "            self.interval_array[left_range, 1]   = max(new_left_interval)\n",
    "            self.interval_array[right_range, 0]  = min(new_right_interval)\n",
    "            self.interval_array[right_range, 1]  = max(new_right_interval)\n",
    "            \n",
    "\n",
    "            return()\n",
    "\n",
    "        # if the cell only branches on side side instead of two or none. \n",
    "        elif (len(left_range) == 1 or len(right_range) == 1): \n",
    "            current_interval, _, _, _ = hpd_grid(sample = beta_deviates, alpha = self.credmass_per_cell, \n",
    "                                                 roundto=4)\n",
    "\n",
    "            # Deshelling, as by default the current interval is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "\n",
    "            \n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "\n",
    "            \n",
    "            current_inverse_interval = (1 - current_interval[::-1])\n",
    "\n",
    "\n",
    "            new_left_interval = previous_interval * current_inverse_interval \n",
    "\n",
    "            self.level += 1\n",
    "            self.construct_tree(left_range, new_left_interval)                    \n",
    "            self.level -= 1\n",
    "            \n",
    "            # append(credibility_regions, current_interval)\n",
    "            \n",
    "            self.interval_array[right_range, 0]  =  min(current_interval)\n",
    "            self.interval_array[right_range, 1]  =  max(current_interval)        \n",
    "            \n",
    "            return()\n",
    "\n",
    "        elif valid_range is None:  # if we are at the root and ... XXX TODO commenting\n",
    "            \n",
    "            current_interval, _, _, _ = hpd_grid(sample = beta_deviates, alpha = self.credmass_per_cell, \n",
    "                                                 roundto=4)\n",
    "       \n",
    "            # Deshelling, as by default the current interval is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "            \n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "            \n",
    "            current_inverse_interval = (1 - current_interval[::-1])\n",
    "\n",
    "            new_left_interval = current_inverse_interval \n",
    "            new_right_interval = current_interval\n",
    "\n",
    "            self.level += 1\n",
    "            self.construct_tree(left_range,  new_left_interval)                       # the one on the left\n",
    "            self.construct_tree(right_range, new_right_interval)                 # the one on the right\n",
    "            self.level -= 1\n",
    "            \n",
    "   \n",
    "            return()\n",
    "\n",
    "\n",
    "        # if we are branching twice i.e. the standard case with an intermediary node.\n",
    "        else:\n",
    "            current_interval, _, _, _ = hpd_grid(sample = beta_deviates, alpha = self.credmass_per_cell, \n",
    "                                                 roundto=4)\n",
    "\n",
    "            # Deshelling, as by default the current interval is a tuple inside a list...\n",
    "            current_interval = [item for t in current_interval for item in t]\n",
    "\n",
    "            \n",
    "            current_interval = np.array([min(current_interval), max(current_interval)])  \n",
    "\n",
    "            current_inverse_interval = (1 - current_interval[::-1])\n",
    "                        \n",
    "            new_left_interval = previous_interval * current_inverse_interval \n",
    "            new_right_interval = previous_interval *  current_interval\n",
    "              \n",
    "            # send them up\n",
    "            self.level += 1\n",
    "            self.construct_tree(left_range, new_left_interval)        # the one on the left\n",
    "            self.construct_tree(right_range,  new_right_interval ) # the one on the right\n",
    "            self.level -= 1\n",
    "\n",
    "            return()\n",
    "        \n",
    "        \n",
    "        # Once the recursion is done and the first function returns, we have to reset self.level. \n",
    "        self.level = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:43:37.927887Z",
     "start_time": "2020-04-26T15:43:37.332443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 99.0% confidence, the intervals are:\n",
      "--------------------------------------\n",
      "Black \n",
      " lower 0.001051338600000002 \n",
      " upper  0.099821082\n",
      "\n",
      "\n",
      "Brown \n",
      " lower 0.11544318299999996 \n",
      " upper  0.4246149244\n",
      "\n",
      "\n",
      "Blonde \n",
      " lower 0.21447885239999998 \n",
      " upper  0.5453589688000001\n",
      "\n",
      "\n",
      "Red \n",
      " lower 0.2048894352 \n",
      " upper  0.5311289706000001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_obj = Tree_Inference_Object(observation_array= np.array([3, 40, 61, 59]), \n",
    "                                 labels = [\"Black\", \"Brown\", \"Blonde\", \"Red\"],\n",
    "                                 confidence= 0.99, granularity=  10**4)\n",
    "\n",
    "\n",
    "\n",
    "test_obj.construct_tree()\n",
    "test_obj.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:43:39.400144Z",
     "start_time": "2020-04-26T15:43:39.260510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Black',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Black',\n",
       " 'Brown',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Red',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Blonde',\n",
       " 'Red',\n",
       " 'Brown',\n",
       " 'Blonde']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_obj.get_tree_sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:44:40.450011Z",
     "start_time": "2020-04-26T15:44:40.447019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Maybe experiment with different priors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
